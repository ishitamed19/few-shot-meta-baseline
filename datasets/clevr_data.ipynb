{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import collections, os, io\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised..... 1080  files...\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/projects/katefgroup/datasets/clevr_vqa/raw/npys/multi_obj_480_at.txt'\n",
    "\n",
    "if root_dir.endswith(\"txt\"):\n",
    "    data  = []\n",
    "\n",
    "    with open(root_dir) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data.append(line.split()[0])\n",
    "\n",
    "    all_files = [os.path.join(os.path.dirname(root_dir),f) for f in data if f.endswith('.p')]\n",
    "else:\n",
    "    all_files = [os.path.join(root_dir,f) for f in os.listdir(root_dir) if f.endswith('.p')]\n",
    "\n",
    "all_files.sort(); \n",
    "\n",
    "print('Initialised.....',len(all_files),' files...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/katefgroup/datasets/clevr_vqa/raw/npys/multi_obj_480_a/multi_obj_480_a_15905204534515152.p'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(all_files[0], \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rotation_list', 'color_list', 'shape_list', 'material_list', 'bbox_origin', 'bbox_camR', 'camR_T_origin_raw', 'xyz_camXs_raw', 'origin_T_camXs_raw', 'rgb_camXs_raw', 'pix_T_cams_raw'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 320, 480, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rgb_camXs_raw'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['green', 'purple', 'blue', 'yellow', 'blue', 'red', 'yellow']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['color_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_B = 1\n",
    "hyp_N = 7\n",
    "hyp_S = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "__p = lambda x: utils_disco.pack_seqdim(x, hyp_B)\n",
    "__u = lambda x: utils_disco.unpack_seqdim(x, hyp_B)\n",
    "__pb = lambda x: utils_disco.pack_boxdim(x, hyp_N)\n",
    "__ub = lambda x: utils_disco.unpack_boxdim(x, hyp_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = torch.from_numpy(np.reshape(np.arange(hyp_B*hyp_N),[hyp_B,hyp_N]))\n",
    "pix_T_cams = torch.from_numpy(data[\"pix_T_cams_raw\"][0]).reshape(hyp_B, hyp_S, 4, 4).cuda()\n",
    "\n",
    "camRs_T_origin = data['camR_T_origin_raw'][0]\n",
    "camRs_T_origin = torch.from_numpy(camRs_T_origin).reshape(hyp_B, hyp_S, 4, 4).cuda()\n",
    "\n",
    "origin_T_camRs = __u(utils_disco.safe_inverse(__p(camRs_T_origin)))\n",
    "\n",
    "origin_T_camXs = torch.from_numpy(data['origin_T_camXs_raw'][0]).reshape(hyp_B, hyp_S, 4, 4).cuda()\n",
    "camX0_T_camXs = utils_disco.get_camM_T_camXs(origin_T_camXs, ind=0)\n",
    "camRs_T_camXs = __u(torch.matmul(utils_disco.safe_inverse(__p(origin_T_camRs)), __p(origin_T_camXs))) \n",
    "\n",
    "camXs_T_camRs = __u(utils_disco.safe_inverse(__p(camRs_T_camXs)))\n",
    "camX0_T_camRs = camXs_T_camRs[:,0]\n",
    "\n",
    "camR_T_camX0  = utils_disco.safe_inverse(camX0_T_camRs)\n",
    "\n",
    "rgb_camXs = data[\"rgb_camXs_raw\"][:,:,:,:3]\n",
    "rgb_camX0 = torch.from_numpy(rgb_camXs[0]).permute(2,0,1).reshape(hyp_B, 3, 320, 480) #torch.from_numpy(np.fliplr(rgb_camXs[0,0])).reshape(1, 256, 256, 3).permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bbox_camR'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, Y, X = 144, 144, 144\n",
    "Z2, Y2, X2 = int(Z/2), int(Y/2), int(X/2)\n",
    "Z4, Y4, X4 = int(Z/4), int(Y/4), int(X/4)\n",
    "\n",
    "import utils_vox\n",
    "\n",
    "gt_boxesR_corners = torch.from_numpy(data['bbox_camR']).reshape(hyp_B, hyp_N, 8, 3).cuda()\n",
    "\n",
    "gt_boxesRMem_corners = __ub(utils_vox.Ref2Mem(__pb(gt_boxesR_corners),Z2,Y2,X2))\n",
    "gt_boxesRMem_end = utils_disco.get_ends_of_corner(gt_boxesRMem_corners) \n",
    "\n",
    "gt_boxesRMem_theta = utils_disco.transform_corners_to_boxes(gt_boxesRMem_corners)\n",
    "gt_boxesRUnp_corners = __ub(utils_vox.Ref2Mem(__pb(gt_boxesR_corners),Z,Y,X))\n",
    "\n",
    "gt_boxesRUnp_end = utils_disco.get_ends_of_corner(gt_boxesRUnp_corners)\n",
    "\n",
    "gt_boxesX0_corners = __ub(utils_disco.apply_4x4(camX0_T_camRs, __pb(gt_boxesR_corners)))\n",
    "\n",
    "gt_boxesXs_corners = __u(__ub(utils_disco.apply_4x4(__p(camXs_T_camRs), __p(__pb(gt_boxesR_corners).unsqueeze(1).repeat(1,hyp_S,1,1)) )))\n",
    "gt_boxesXs_end = __u(utils_disco.get_ends_of_corner(__p(gt_boxesXs_corners)))\n",
    "\n",
    "gt_boxesX0Mem_corners = __ub(utils_vox.Ref2Mem(__pb(gt_boxesX0_corners),Z2,Y2,X2))\n",
    "gt_boxesX0Mem_theta = utils_disco.transform_corners_to_boxes(gt_boxesX0Mem_corners)\n",
    "gt_boxesX0Mem_end = utils_disco.get_ends_of_corner(gt_boxesX0Mem_corners)\n",
    "gt_boxesX0_end = utils_disco.get_ends_of_corner(gt_boxesX0_corners)  \n",
    "\n",
    "gt_cornersX0_pix = __ub(utils_disco.apply_pix_T_cam(__p(pix_T_cams), __pb(gt_boxesX0_corners)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_corners_on_image(rgb, corners_cam, scores, tids, pix_T_cam,info_text=None):\n",
    "    # first we need to get rid of invalid gt boxes\n",
    "    # gt_boxes = trim_gt_boxes(gt_boxes)\n",
    "    B, C, H, W = list(rgb.shape)\n",
    "    assert(C==3)\n",
    "    B2, N, D, E = list(corners_cam.shape)\n",
    "    assert(B2==B)\n",
    "    assert(D==8) # 8 corners\n",
    "    assert(E==3) # 3D\n",
    "\n",
    "    #rgb = back2color(rgb)\n",
    "    corners_cam_ = torch.reshape(corners_cam, [B, N*8, 3])\n",
    "    corners_pix_ = utils_disco.apply_pix_T_cam(pix_T_cam, corners_cam_)\n",
    "    corners_pix = torch.reshape(corners_pix_, [B, N, 8, 2])\n",
    "    out = draw_boxes_on_image_py(rgb[0].cpu().numpy(),\n",
    "                                      corners_pix[0].cpu().numpy(),\n",
    "                                      scores[0].cpu().numpy(),\n",
    "                                      tids[0].cpu().numpy(),info_text)\n",
    "    out = torch.from_numpy(out).type(torch.ByteTensor).permute(2, 0, 1)\n",
    "    out = torch.unsqueeze(out, dim=0)\n",
    "    #out = preprocess_color(out)\n",
    "    out = torch.reshape(out, [1, C, H, W])\n",
    "    return out, corners_pix\n",
    "\n",
    "def draw_boxes_on_image_py(rgb, corners_pix, scores, tids,info_text=None, boxes=None, thickness=1,text=False):\n",
    "    # all inputs are numpy tensors\n",
    "    # rgb is H x W x 3\n",
    "    # corners_pix is N x 8 x 2, in xy order\n",
    "    # scores is N\n",
    "    # tids is N\n",
    "    # boxes is N x 9 < this is only here to print some rotation info\n",
    "    # pix_T_cam is 4 x 4\n",
    "    rgb = np.transpose(rgb, [1, 2, 0]) # put channels last\n",
    "    \n",
    "\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "   \n",
    "  \n",
    "\n",
    "    H, W, C = rgb.shape\n",
    "    assert(C==3)\n",
    "    N, D, E = corners_pix.shape\n",
    "    assert(D==8)\n",
    "    assert(E==2)\n",
    "\n",
    "    if boxes is not None:\n",
    "        rx = boxes[:,6]\n",
    "        ry = boxes[:,7]\n",
    "        rz = boxes[:,8]\n",
    "    else:\n",
    "        rx = 0\n",
    "        ry = 0\n",
    "        rz = 0\n",
    "\n",
    "    color_map = matplotlib.cm.get_cmap('tab20')\n",
    "    color_map = color_map.colors\n",
    "\n",
    "    # draw\n",
    "    for ind, corners in enumerate(corners_pix):\n",
    "        # corners is 8 x 2\n",
    "        # st()\n",
    "        if not np.isclose(scores[ind], 0.0):\n",
    "            # print 'score = %.2f' % scores[ind]\n",
    "            color_id = tids[ind] % 20\n",
    "            color = color_map[2]\n",
    "            color_text = color_map[2]\n",
    "\n",
    "            # st()\n",
    "\n",
    "            color = np.array(color)*255.0\n",
    "            # print 'tid = %d; score = %.3f' % (tids[ind], scores[ind])\n",
    "            if info_text is not None:\n",
    "                text_to_put = info_text[ind]\n",
    "                cv2.putText(rgb,\n",
    "                            text_to_put, \n",
    "                            (np.min(corners[:,0]), np.min(corners[:,1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, # font size\n",
    "                            color_text,\n",
    "                            2) # font weight\n",
    "\n",
    "            for c in corners:\n",
    "\n",
    "                # rgb[pt1[0], pt1[1], :] = 255\n",
    "                # rgb[pt2[0], pt2[1], :] = 255\n",
    "                # rgb[np.clip(int(c[0]), 0, W), int(c[1]), :] = 255\n",
    "\n",
    "                c0 = np.clip(int(c[0]), 0,  W-1)\n",
    "                c1 = np.clip(int(c[1]), 0,  H-1)\n",
    "                rgb[c1, c0, :] = 255\n",
    "\n",
    "            # we want to distinguish between in-plane edges and out-of-plane ones\n",
    "            # so let's recall how the corners are ordered:\n",
    "            xs = np.array([-1/2., -1/2., -1/2., -1/2., 1/2., 1/2., 1/2., 1/2.])\n",
    "            ys = np.array([-1/2., -1/2., 1/2., 1/2., -1/2., -1/2., 1/2., 1/2.])\n",
    "            zs = np.array([-1/2., 1/2., -1/2., 1/2., -1/2., 1/2., -1/2., 1/2.])\n",
    "            xs = np.reshape(xs, [8, 1])\n",
    "            ys = np.reshape(ys, [8, 1])\n",
    "            zs = np.reshape(zs, [8, 1])\n",
    "            offsets = np.concatenate([xs, ys, zs], axis=1)\n",
    "\n",
    "            corner_inds = list(range(8))\n",
    "            combos = list(combinations(corner_inds, 2))\n",
    "\n",
    "            for combo in combos:\n",
    "                pt1 = offsets[combo[0]]\n",
    "                pt2 = offsets[combo[1]]\n",
    "                # draw this if it is an in-plane edge\n",
    "                eqs = pt1==pt2\n",
    "                if np.sum(eqs)==2:\n",
    "                    i, j = combo\n",
    "                    pt1 = (corners[i, 0], corners[i, 1])\n",
    "                    pt2 = (corners[j, 0], corners[j, 1])\n",
    "                    print(W, H, pt1, pt2)\n",
    "                    retval, pt1, pt2 = cv2.clipLine((0, 0, W, H), int(pt1), int(pt2))\n",
    "                    if retval:\n",
    "                        cv2.line(rgb, pt1, pt2, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "                    # rgb[pt1[0], pt1[1], :] = 255\n",
    "                    # rgb[pt2[0], pt2[1], :] = 255\n",
    "    rgb = cv2.cvtColor(rgb.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    # utils_basic.print_stats_py('rgb_uint8', rgb)\n",
    "    # imageio.imwrite('boxes_rgb.png', rgb)\n",
    "    return rgb\n",
    "\n",
    "def summ_box_by_corners(rgbR, corners, scores, tids, pix_T_cam, only_return=False):\n",
    "    # rgb is B x H x W x C\n",
    "    # corners is B x N x 8 x 3 \n",
    "    # scores is B x N\n",
    "    # tids is B x N\n",
    "    # pix_T_cam is B x 4 x 4\n",
    "    # st()\n",
    "    B, C, H, W = list(rgbR.shape)\n",
    "    boxes_vis = draw_corners_on_image(rgbR,corners,scores,tids,pix_T_cam,None)\n",
    "    return boxes_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = (cv::impl::<unnamed>::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 4 (CV_32S)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9dccaa05ea9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboxes_vis_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorners_pix_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msumm_box_by_corners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_camX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxesX0_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyp_N\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpix_T_cams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mboxes_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhyp_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c189107d0440>\u001b[0m in \u001b[0;36msumm_box_by_corners\u001b[0;34m(rgbR, corners, scores, tids, pix_T_cam, only_return)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# st()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgbR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mboxes_vis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_corners_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgbR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorners\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpix_T_cam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mboxes_vis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c189107d0440>\u001b[0m in \u001b[0;36mdraw_corners_on_image\u001b[0;34m(rgb, corners_cam, scores, tids, pix_T_cam, info_text)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                       \u001b[0mcorners_pix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                       \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                       tids[0].cpu().numpy(),info_text)\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c189107d0440>\u001b[0m in \u001b[0;36mdraw_boxes_on_image_py\u001b[0;34m(rgb, corners_pix, scores, tids, info_text, boxes, thickness, text)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = (cv::impl::<unnamed>::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 4 (CV_32S)\n"
     ]
    }
   ],
   "source": [
    "boxes_vis_q, corners_pix_q = summ_box_by_corners(rgb_camX0, gt_boxesX0_corners, torch.from_numpy(np.ones([1,hyp_N])), tids, __p(pix_T_cams))\n",
    "\n",
    "\n",
    "boxes_q = torch.zeros([hyp_N, 4])\n",
    "\n",
    "for n in range(hyp_N):\n",
    "    boxes_q[n][0] = torch.min(corners_pix_q[0, n, :, 0]) \n",
    "    boxes_q[n][1] = torch.min(corners_pix_q[0, n, :, 1]) \n",
    "    boxes_q[n][2] = torch.max(corners_pix_q[0, n, :, 0]) \n",
    "    boxes_q[n][3] = torch.max(corners_pix_q[0, n, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchNew",
   "language": "python",
   "name": "torchnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
